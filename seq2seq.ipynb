{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tokenization\n",
    "import collections\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['character1','character2','movietitle','conversation']\n",
    "\n",
    "movie_conver = []\n",
    "with open('data/movie_conversations.txt','r') as file:\n",
    "    for l in file:\n",
    "        lines = l.split('+++$+++')\n",
    "        line_content =  eval(lines[-1].rstrip())\n",
    "        lines = [x.strip() for x in lines[:-1]]\n",
    "        lines.append(line_content)\n",
    "        movie_conver.append(lines)\n",
    "movie_conver = pd.DataFrame(movie_conver, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['line','character_id','movietitle','character_name','text']\n",
    "\n",
    "movie_lines = []\n",
    "with open('data/movie_lines.txt','r', errors='ignore') as file:\n",
    "    for l in file:\n",
    "        lines = l.split('+++$+++')\n",
    "        lines[-1] = lines[-1].rstrip()\n",
    "        lines = [x.strip() for x in lines]\n",
    "        movie_lines.append(lines)\n",
    "movie_lines = pd.DataFrame(movie_lines, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(movie_lines['line'].unique()) == len(movie_lines['line'])\n",
    "movie_lines.set_index('line',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example():\n",
    "    \n",
    "    def __init__(self,input_sentences, output_sentences):\n",
    "        \n",
    "        self.input_sentences = input_sentences\n",
    "        self.output_sentences = output_sentences\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_toIndex(tokens, word_dict):\n",
    "\n",
    "    index_features = []\n",
    "    for token in tokens:\n",
    "        if not token in word_dict:\n",
    "            word_dict[token] = len(word_dict) + 1\n",
    "\n",
    "        index_features.append(word_dict[token])\n",
    "    return index_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_sequence(text_a, text_b, max_len):\n",
    "    \n",
    "    while len(text_a) + len(text_b) + 3 >= max_len:\n",
    "        if len(text_b) > len(text_a):\n",
    "            text_b.pop()\n",
    "        else:\n",
    "            text_a.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_toExample(num_i, conversation, tokenizer, max_input_seq, max_output_seq, word_dict):\n",
    "#     convert text into examples\n",
    "    \n",
    "    num_convers = len(conversation)\n",
    "    for i, _ in enumerate(conversation):\n",
    "        \n",
    "        if i < num_convers - 2:\n",
    "            num_i += 1\n",
    "            \n",
    "            text_q = tokenizer.tokenize(conversation[i])\n",
    "            text_p = tokenizer.tokenize(conversation[i+1])\n",
    "            response = tokenizer.tokenize(conversation[i+2])\n",
    "            \n",
    "            truncate_sequence(text_q, text_p, max_input_seq)   \n",
    "            \n",
    "            input_texts = text_q + ['[SEQ]'] + text_p\n",
    "            \n",
    "            if len (response) > max_output_seq - 2:\n",
    "                response = response[:max_output_seq - 2]\n",
    "                \n",
    "            response = ['[START]'] + response + ['[END]']\n",
    "        \n",
    "            input_id = convert_toIndex(input_texts, word_dict)\n",
    "            output_id = convert_toIndex(response, word_dict)\n",
    "            \n",
    "            if len(input_id) < max_input_seq:\n",
    "                input_id.extend([0] * (max_input_seq - len(input_id)))\n",
    "                \n",
    "            if len(output_id) < max_output_seq:\n",
    "                output_id.extend([0] * (max_output_seq - len(output_id)))\n",
    "                \n",
    "            assert len(input_id) == max_input_seq\n",
    "            assert len(output_id) == max_output_seq\n",
    "            \n",
    "            if num_i % 5000 == 0:\n",
    "                tf.logging.info('input text: %s' % ' '.join(input_texts))\n",
    "                tf.logging.info('input id: %s' % ' '.join([str(x) for x in input_id]))\n",
    "                tf.logging.info('output text: %s' % ' '.join(response))\n",
    "                tf.logging.info('output id: %s' % ' '.join([ str(x) for x in output_id]))\n",
    "            \n",
    "            yield num_i, Example(input_id, output_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataSet(movie_conver, movie_lines, max_input_seq, max_output_seq, tokenizer):\n",
    "    \n",
    "    word_dict = collections.OrderedDict()\n",
    "    output_file = 'data/record'\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "    num_i = 0\n",
    "    \n",
    "    for index, row in movie_conver.iterrows():\n",
    "        line_index = row['conversation']\n",
    "        conversation = movie_lines.loc[line_index,'text']\n",
    "        \n",
    "        if len(conversation) > 2:\n",
    "            for num_i, example in convert_toExample(num_i, conversation, tokenizer, max_input_seq, max_output_seq, word_dict):\n",
    "    #             input_texts, response, input_id, output_id = text_info\n",
    "  \n",
    "    \n",
    "                features = collections.OrderedDict()\n",
    "                features[\"input_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=example.input_sentences))\n",
    "                features[\"output_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=example.output_sentences))\n",
    "\n",
    "                tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    return word_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer('data/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input text: what do you think ' s gonna go on at the guys ' party ? [SEQ] they ' ll probably get drunk , and watch dirty movies . but don ' t worry about the dirty movies .\n",
      "INFO:tensorflow:input id: 208 205 42 245 33 40 238 151 157 78 46 278 33 193 6 28 474 33 298 1599 93 751 30 13 1677 3606 712 43 152 130 33 69 1468 221 46 3606 712 43 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] what do you mean ? [END]\n",
      "INFO:tensorflow:output id: 44 208 205 42 254 6 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: the indian rope - trick . [SEQ] look , now i ' m pumping you . i ' m sorry . it ' s none of my business . it ' s just that you ' re not like the others .\n",
      "INFO:tensorflow:input id: 46 2328 8526 26 3735 43 28 642 30 375 31 33 77 7805 42 43 31 33 77 951 43 65 33 40 2809 80 66 1917 43 65 33 40 111 39 42 33 126 45 91 46 1169 43 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] not like matt , you mean . [END]\n",
      "INFO:tensorflow:output id: 44 45 91 4350 30 42 254 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: you ' re saying they mu ##tin ##ied for the gold ? [SEQ] if they were close enough to shore , they probably figured they could get away in the lifeboat ##s .\n",
      "INFO:tensorflow:input id: 42 33 126 1347 474 3546 2339 9054 128 46 1184 6 28 38 474 430 2364 95 102 11507 30 474 1599 226 474 92 93 405 167 46 10453 317 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] only something must ' ve gone wrong . [END]\n",
      "INFO:tensorflow:output id: 44 365 115 429 33 184 709 770 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: not in love , exactly , but . . . [SEQ] well forgive me if i don ' t think of you as the world ' s safe ##st bet .\n",
      "INFO:tensorflow:input id: 45 167 1063 30 260 30 152 43 43 43 28 29 1224 200 38 31 130 33 69 245 80 42 376 46 1180 33 40 2097 4239 2194 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] would you marry me if i was ? [END]\n",
      "INFO:tensorflow:output id: 44 398 42 1207 200 38 31 110 6 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: you ain ' t got to do nothing . just point at it and push the button . you ' ll hear the car go \" b ##lee ##p . \" that means the alarm ' s off and the doors are open . [SEQ] okay .\n",
      "INFO:tensorflow:input id: 42 2304 33 69 112 102 205 890 43 111 1048 78 65 13 4531 46 478 43 42 33 298 218 46 676 151 196 1024 11928 1578 43 196 39 314 46 4895 33 40 763 13 46 2294 16 1646 43 28 41 43 0 0 0\n",
      "INFO:tensorflow:output text: [START] now play the volume as loud as you want but don ' t touch my levels . i got them set just the [END]\n",
      "INFO:tensorflow:output id: 44 375 1016 46 6351 376 5742 376 42 131 152 130 33 69 1079 66 11021 43 31 112 452 412 111 46 53\n",
      "INFO:tensorflow:input text: john said something about him being set up because he \" found out about her . \" [SEQ] we know why john was tagged .\n",
      "INFO:tensorflow:input id: 3130 377 115 221 161 1336 412 27 144 246 196 163 58 221 168 43 196 28 2 132 96 3130 110 14623 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] he also said crow was a fake . [END]\n",
      "INFO:tensorflow:output id: 44 246 1128 377 7801 110 71 3206 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: here ' s my passport . . . . please give me a visa . i have to leave for russia immediately . [SEQ] count leon d ' al ##go ##ut . . . a count ! . . . a nobleman !\n",
      "INFO:tensorflow:input id: 247 33 40 66 7902 43 43 43 43 52 281 200 71 7876 43 31 70 102 839 128 7870 2177 43 28 677 1770 34 33 567 7244 3048 43 43 43 71 677 217 43 43 43 71 4786 217 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] don ' t hold that against me . . . please ! [END]\n",
      "INFO:tensorflow:output id: 44 130 33 69 1797 39 1397 200 43 43 43 52 217 53 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: you shouldn ' t monkey with him . [SEQ] what ?\n",
      "INFO:tensorflow:input id: 42 1909 33 69 4828 36 161 43 28 208 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] he ' s a wheel . so ' s she . it ' s hard to make friends with them . [END]\n",
      "INFO:tensorflow:output id: 44 246 33 40 71 4268 43 170 33 40 88 43 65 33 40 307 102 3 435 36 452 43 53 0 0\n",
      "INFO:tensorflow:input text: permission granted . [SEQ] thank you , admiral .\n",
      "INFO:tensorflow:input id: 865 3555 43 28 215 42 30 1117 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] jim , sp ##ock , jim . remember . . . ? [END]\n",
      "INFO:tensorflow:output id: 44 4072 30 3322 7898 30 4072 43 1255 43 43 43 6 53 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: now , my little coconut , what seems to be the trouble here ? tell daddy everything . [SEQ] jimmy , my daddy ' s still alive and it kind of gives me the creep ##s when you do that . . .\n",
      "INFO:tensorflow:input id: 375 30 66 475 6585 30 208 90 102 103 46 2265 247 6 394 419 1254 43 28 3760 30 66 419 33 40 882 1422 13 65 177 80 1842 200 46 7863 317 106 42 205 39 43 43 43 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] okay , okay , just tell me what ' s the trouble . [END]\n",
      "INFO:tensorflow:output id: 44 41 30 41 30 111 394 200 208 33 40 46 2265 43 53 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: but john hasn ' t got any . [SEQ] what ?\n",
      "INFO:tensorflow:input id: 152 3130 2026 33 69 112 448 43 28 208 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] nerves . [END]\n",
      "INFO:tensorflow:output id: 44 8192 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: am i at the same angle to you and the basket as before ? [SEQ] yeah .\n",
      "INFO:tensorflow:input id: 1150 31 78 46 174 894 102 42 13 46 7929 376 188 6 28 284 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] are you ? [END]\n",
      "INFO:tensorflow:output id: 44 16 42 6 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: shit , that was fast . [SEQ] 12 - year olds . they scare easy . anyway , he ' s gonna tip their st ##ash . come with me .\n",
      "INFO:tensorflow:input id: 533 30 39 110 2197 43 28 5545 26 710 11355 43 474 451 94 43 768 30 246 33 40 238 4151 524 1247 2503 43 482 36 200 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] i ' m on my way home . can you handle it yourself ? [END]\n",
      "INFO:tensorflow:output id: 44 31 33 77 157 66 786 353 43 1 42 2151 65 785 6 53 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: well , all the same . if we get to miss ##ou ##la , help me find a car . i ' d appreciate it . then . . . you can . . . [SEQ] . . . split .\n",
      "INFO:tensorflow:input id: 29 30 183 46 174 43 38 2 93 102 1644 5762 1818 30 698 200 844 71 676 43 31 33 34 734 65 43 54 43 43 43 42 1 43 43 43 28 43 43 43 2068 43 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] split ? i wouldn ' t get ten . . . [END]\n",
      "INFO:tensorflow:output id: 44 2068 6 31 862 33 69 93 1387 43 43 43 53 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: he made you give him a blow job . [SEQ] no .\n",
      "INFO:tensorflow:input id: 246 1492 42 281 161 71 605 1094 43 28 64 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] well what then ? [END]\n",
      "INFO:tensorflow:output id: 44 29 208 54 6 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: you don ' t se ##w at all ! [SEQ] a woman should never learn to se ##w , and if she can she should never admit to it . close your eyes .\n",
      "INFO:tensorflow:input id: 42 130 33 69 2707 1331 78 183 217 28 71 1372 859 198 240 102 2707 1331 30 13 38 88 1 88 859 198 1010 102 65 43 2364 222 809 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] that makes it harder still . [END]\n",
      "INFO:tensorflow:output id: 44 39 559 65 2907 882 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: what the hell . . . [SEQ] i ' m dreaming this . shit , this is a dream .\n",
      "INFO:tensorflow:input id: 208 46 626 43 43 43 28 31 33 77 3835 4 43 533 30 4 76 71 3329 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] i ' m not dreaming . [END]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output id: 44 31 33 77 45 3835 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: jesus . . . jesus ! [SEQ] oh , god , i don ' t even know what i want .\n",
      "INFO:tensorflow:input id: 1098 43 43 43 1098 217 28 311 30 216 30 31 130 33 69 340 132 208 31 131 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] oh . . . [END]\n",
      "INFO:tensorflow:output id: 44 311 43 43 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: marc ##ee , things are changing around here . you and rod will have my total personal attention . [SEQ] damn right , and you can start by taking rod ' s poster and putting it where people can see it !\n",
      "INFO:tensorflow:input id: 10872 5643 30 136 16 4036 1131 247 43 42 13 458 411 70 66 373 2437 787 43 28 1345 124 30 13 42 1 35 506 765 458 33 40 10935 13 1517 65 137 410 1 125 65 217 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] damn right . [END]\n",
      "INFO:tensorflow:output id: 44 1345 124 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: what will you do ? [SEQ] i have to go back to birmingham .\n",
      "INFO:tensorflow:input id: 208 411 42 205 6 28 31 70 102 151 192 102 20334 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] is crawford going with you ? [END]\n",
      "INFO:tensorflow:output id: 44 76 11439 272 36 42 6 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: thanks . [SEQ] don ' t say much , do you ?\n",
      "INFO:tensorflow:input id: 2268 43 28 130 33 69 133 140 30 205 42 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] guess i don ' t . [END]\n",
      "INFO:tensorflow:output id: 44 348 31 130 33 69 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: rise and report . [SEQ] the thieves ' forest is emptied . thirty men guard the castle gate .\n",
      "INFO:tensorflow:input id: 1282 13 1684 43 28 46 1279 33 1389 76 5582 43 510 1302 3764 46 5260 6699 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] double it . my princess must be safe . [END]\n",
      "INFO:tensorflow:output id: 44 3357 65 43 66 5006 429 103 2097 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: what part of ' off the record ' don ' t you understand ? [SEQ] right . sorry . do you think he did it ?\n",
      "INFO:tensorflow:input id: 208 51 80 33 763 46 4306 33 130 33 69 42 997 6 28 124 43 951 43 205 42 245 246 201 65 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] i ' ve got my suspicions but still , nothing you say can ever make me take my eyes off one person . [END]\n",
      "INFO:tensorflow:output id: 44 31 33 184 112 66 15367 152 882 30 890 42 133 1 185 3 200 662 66 809 763 147 960 43 53\n",
      "INFO:tensorflow:input text: how ' s that ? [SEQ] i was doing the lamb ##ada with her and the guy freaks , he breaks my arm , tries to kill me . i swear man , the guy thought i was a pia ##ta . if nobody else hadn '\n",
      "INFO:tensorflow:input id: 55 33 40 39 6 28 31 110 358 46 5326 12643 36 168 13 46 178 10357 30 246 3907 66 3696 30 11035 102 825 200 43 31 1211 344 30 46 178 32 31 110 71 14987 1621 43 38 1751 362 1601 33 0 0 0\n",
      "INFO:tensorflow:output text: [START] uh . . . over easy . [END]\n",
      "INFO:tensorflow:output id: 44 699 43 43 43 643 94 43 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: probably . sarah , if i get zero ##ed . . . [SEQ] don ' t say that .\n",
      "INFO:tensorflow:input id: 1599 43 719 30 38 31 93 2996 829 43 43 43 28 130 33 69 133 39 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] if i do , you have to get away , disappear without a trace . different country , different name , everything . [END]\n",
      "INFO:tensorflow:output id: 44 38 31 205 30 42 70 102 93 405 30 6013 870 71 9657 43 267 1299 30 267 794 30 1254 43 53\n",
      "INFO:tensorflow:input text: no , but we ' re making excellent time . [SEQ] captain , the press knows the size of titanic , let them marvel at her speed too . we must give them something new to print . and the maiden voyage of titanic must make headlines\n",
      "INFO:tensorflow:input id: 64 30 152 2 33 126 636 2943 914 43 28 2269 30 46 1573 182 46 2434 80 13562 30 395 452 2252 78 168 4081 334 43 2 429 281 452 115 497 102 8756 43 13 46 10416 1138 80 13562 429 3 10973 0 0 0\n",
      "INFO:tensorflow:output text: [START] i prefer not to push the engines until they ' ve been properly run in . [END]\n",
      "INFO:tensorflow:output id: 44 31 2683 45 102 4531 46 3580 87 474 33 184 203 9296 692 167 43 53 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: hear what ? [SEQ] that it was all an accident . she wants to hear it from mic ##hea ##l ' s mouth .\n",
      "INFO:tensorflow:input id: 218 208 6 28 39 65 110 183 18 3769 43 88 868 102 218 65 502 13725 6454 1855 33 40 1967 43 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] now ? [END]\n",
      "INFO:tensorflow:output id: 44 375 6 53 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "max_input_seq = 50\n",
    "max_output_seq = 25\n",
    "\n",
    "word_dict = build_dataSet(movie_conver, movie_lines, max_input_seq, max_output_seq, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del movie_conver\n",
    "del movie_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/vocab.json', 'w') as fp:\n",
    "    json.dump(word_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_DataSet(input_file, input_length, output_length, batch_size = 32):\n",
    "    \n",
    "    feature_description = {\n",
    "      \"input_ids\": tf.FixedLenFeature([input_length], tf.int64),\n",
    "      \"output_ids\": tf.FixedLenFeature([output_length], tf.int64),\n",
    "      }\n",
    "    \n",
    "    def _parse_function(record):\n",
    "        return tf.parse_single_example(record, feature_description)\n",
    "    \n",
    "    \n",
    "    data = tf.data.TFRecordDataset(input_file)\n",
    "    data = data.map(lambda x: _parse_function(x))\n",
    "    \n",
    "    data = data.shuffle(buffer_size=1000).batch(batch_size)\n",
    "    data = data.cache()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_ids, vocab_size, embeding_size):\n",
    "    \n",
    "    embeding = tf.get_variable(name = 'word_embedding', shape = [vocab_size, embeding_size], dtype = tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "    input_embeding = tf.nn.embedding_lookup(embeding, input_ids)\n",
    "    \n",
    "    rnn_layers = [tf.nn.rnn_cell.GRUCell(size) for size in [128]]\n",
    "\n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "    \n",
    "    sequence_length = tf.reduce_sum(tf.cast(input_ids > 0, dtype = tf.int32), axis=-1)\n",
    "\n",
    "    outputs, state = tf.nn.dynamic_rnn(multi_rnn_cell, input_embeding, dtype=tf.float32, sequence_length = sequence_length)\n",
    "    \n",
    "    return outputs, state, sequence_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(attention_unit, encoder_output, sequence_length):\n",
    "    \n",
    "    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(attention_unit, memory = encoder_output,\n",
    "                                                               memory_sequence_length=sequence_length)\n",
    "    return attention_mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(output_ids, attention_mechanism, encoder_state, attention_layer_size, reuse = None, training = True):\n",
    "    \n",
    "    with tf.variable_scope('decoder', reuse = reuse):\n",
    "    \n",
    "        output_ids = output_ids[:, :-1]\n",
    "\n",
    "        embeding = tf.get_default_graph().get_tensor_by_name(\"word_embedding:0\")\n",
    "\n",
    "        input_embeding = tf.nn.embedding_lookup(embeding, output_ids)\n",
    "\n",
    "        rnn_layers = [tf.nn.rnn_cell.GRUCell(size) for size in [128]]\n",
    "\n",
    "        multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "\n",
    "        attention_cell = tf.contrib.seq2seq.AttentionWrapper(multi_rnn_cell, attention_mechanism, attention_layer_size = attention_layer_size)\n",
    "        \n",
    "        batch_size = tf.shape(output_ids)[0]\n",
    "\n",
    "        initial_state = attention_cell.zero_state(dtype = tf.float32, batch_size = batch_size)\n",
    "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
    "\n",
    "        decoder_sequence_length = tf.reduce_sum(tf.cast(output_ids > 0, dtype = tf.int32), axis=-1)\n",
    "        \n",
    "        if training:\n",
    "            helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                        inputs = input_embeding, # decoder inputs\n",
    "                        sequence_length = decoder_sequence_length, # decoder input length\n",
    "                        name = \"decoder_training_helper\")\n",
    "        else:\n",
    "            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embeding, start_tokens=tf.zeros([batch_size], dtype=tf.int32) + word_dict['[START]'], end_token=word_dict['[END]'])\n",
    "            \n",
    "\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell = attention_cell,\n",
    "                helper = helper, \n",
    "                initial_state = initial_state)\n",
    "\n",
    "        decoder_outputs, final_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "    \n",
    "    return decoder_outputs, final_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/vocab.json', 'r') as fp:\n",
    "    word_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_file = 'data/record'\n",
    "input_length = 50\n",
    "output_length = 25\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "data = load_DataSet(input_file, input_length, output_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = data.make_initializable_iterator()\n",
    "features = iterator.get_next()\n",
    "\n",
    "input_ids = features['input_ids']\n",
    "output_ids = features['output_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeding_size = 300\n",
    "vocab_size = len(word_dict)\n",
    "attention_unit = 32\n",
    "\n",
    "encoder_output, encoder_state, sequence_length = encoder(input_ids, vocab_size, embeding_size)\n",
    "\n",
    "attention_mechanism = attention(attention_unit, encoder_output, sequence_length)\n",
    "\n",
    "decoder_outputs, final_state = decoder(output_ids, attention_mechanism, encoder_state, attention_layer_size = vocab_size)\n",
    "\n",
    "infer_outputs, _  = decoder(output_ids, attention_mechanism, encoder_state, \n",
    "                                     attention_layer_size = vocab_size, reuse = True, training = False)\n",
    "\n",
    "sequence_length = tf.cast(output_ids[:,1:] > 0, dtype = tf.float32)\n",
    "\n",
    "prob = tf.nn.softmax(decoder_outputs.rnn_output, dim=-1)\n",
    "prediction = infer_outputs.sample_id\n",
    "\n",
    "loss  = tf.contrib.seq2seq.sequence_loss(decoder_outputs.rnn_output, output_ids[:,1:], weights = sequence_length)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "accuracy, accu_update = tf.metrics.accuracy(prediction, output_ids[:,1:], weights = sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epoch):\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(iterator.initializer)\n",
    "        try: \n",
    "            while True:\n",
    "                _, _, los, accu = sess.run([train_op, accu_update, loss, accuracy])\n",
    "                print(accu)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
