{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tokenization\n",
    "import collections\n",
    "import ast\n",
    "import time\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['character1','character2','movietitle','conversation']\n",
    "\n",
    "movie_conver = []\n",
    "with open('data/movie_conversations.txt','r') as file:\n",
    "    for l in file:\n",
    "        lines = l.split('+++$+++')\n",
    "        line_content =  eval(lines[-1].rstrip())\n",
    "        lines = [x.strip() for x in lines[:-1]]\n",
    "        lines.append(line_content)\n",
    "        movie_conver.append(lines)\n",
    "movie_conver = pd.DataFrame(movie_conver, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['line','character_id','movietitle','character_name','text']\n",
    "\n",
    "movie_lines = []\n",
    "with open('data/movie_lines.txt','r', errors='ignore') as file:\n",
    "    for l in file:\n",
    "        lines = l.split('+++$+++')\n",
    "        lines[-1] = lines[-1].rstrip()\n",
    "        lines = [x.strip() for x in lines]\n",
    "        movie_lines.append(lines)\n",
    "movie_lines = pd.DataFrame(movie_lines, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(movie_lines['line'].unique()) == len(movie_lines['line'])\n",
    "movie_lines.set_index('line',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title = movie_conver['movietitle'].unique()\n",
    "select_title = movie_title[0:10]\n",
    "\n",
    "select_movie_conver = movie_conver[np.isin(movie_conver['movietitle'], select_title)]\n",
    "select_movie_lines = movie_lines[np.isin(movie_lines['movietitle'], select_title)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example():\n",
    "    \n",
    "    def __init__(self,input_sentences, output_sentences):\n",
    "        \n",
    "        self.input_sentences = input_sentences\n",
    "        self.output_sentences = output_sentences\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_toIndex(tokens, word_dict):\n",
    "\n",
    "    index_features = []\n",
    "    for token in tokens:\n",
    "        if not token in word_dict:\n",
    "            word_dict[token] = len(word_dict) + 1\n",
    "\n",
    "        index_features.append(word_dict[token])\n",
    "    return index_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_sequence(text_a, text_b, max_len):\n",
    "    \n",
    "    while len(text_a) + len(text_b) + 3 >= max_len:\n",
    "        if len(text_b) > len(text_a):\n",
    "            text_b.pop()\n",
    "        else:\n",
    "            text_a.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_toExample(num_i, conversation, tokenizer, max_input_seq, max_output_seq, word_dict):\n",
    "#     convert text into examples\n",
    "    \n",
    "    num_convers = len(conversation)\n",
    "    for i, _ in enumerate(conversation):\n",
    "        \n",
    "        if i < num_convers - 1:\n",
    "            num_i += 1\n",
    "            \n",
    "            input_texts = tokenizer.tokenize(conversation[i])\n",
    "            response = tokenizer.tokenize(conversation[i+1])\n",
    "#             response = tokenizer.tokenize(conversation[i+2])          \n",
    "#             truncate_sequence(text_q, text_p, max_input_seq)              \n",
    "#             input_texts = text_q + ['[SEQ]'] + text_p\n",
    "            if len(input_texts) == 0 or len(response) == 0:\n",
    "                continue\n",
    "\n",
    "            if len (input_texts) > max_input_seq:\n",
    "                input_texts = input_texts[:max_output_seq]\n",
    "            \n",
    "            if len (response) > max_output_seq - 2:\n",
    "                response = response[:max_output_seq - 2]\n",
    "                \n",
    "            response = ['[START]'] + response + ['[END]']\n",
    "        \n",
    "            input_id = convert_toIndex(input_texts, word_dict)\n",
    "            output_id = convert_toIndex(response, word_dict)\n",
    "            \n",
    "            if len(input_id) < max_input_seq:\n",
    "                input_id.extend([0] * (max_input_seq - len(input_id)))\n",
    "                \n",
    "            if len(output_id) < max_output_seq:\n",
    "                output_id.extend([0] * (max_output_seq - len(output_id)))\n",
    "                \n",
    "            assert len(input_id) == max_input_seq\n",
    "            assert len(output_id) == max_output_seq\n",
    "            \n",
    "            if num_i % 5000 == 0:\n",
    "                tf.logging.info('input text: %s' % ' '.join(input_texts))\n",
    "                tf.logging.info('input id: %s' % ' '.join([str(x) for x in input_id]))\n",
    "                tf.logging.info('output text: %s' % ' '.join(response))\n",
    "                tf.logging.info('output id: %s' % ' '.join([ str(x) for x in output_id]))\n",
    "            \n",
    "            yield num_i, Example(input_id, output_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataSet(movie_conver, movie_lines, max_input_seq, max_output_seq, tokenizer):\n",
    "    \n",
    "    word_dict = collections.OrderedDict()\n",
    "    num_i = 0\n",
    "    \n",
    "    examples = []\n",
    "    for index, row in movie_conver.iterrows():\n",
    "        line_index = row['conversation']\n",
    "        conversation = movie_lines.loc[line_index,'text']\n",
    "        \n",
    "        if len(conversation) > 2:\n",
    "            for num_i, example in convert_toExample(num_i, conversation, tokenizer, max_input_seq, max_output_seq, word_dict):\n",
    "                examples.append(example)\n",
    "    return word_dict, examples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(examples, file_path):\n",
    "    writer = tf.python_io.TFRecordWriter(file_path)\n",
    "    \n",
    "    for example in examples:\n",
    "        features = collections.OrderedDict()\n",
    "        features[\"input_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=example.input_sentences))\n",
    "        features[\"output_ids\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=example.output_sentences))\n",
    "\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = tokenization.FullTokenizer('data/vocab.txt')\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input text: Thanks for the help .\n",
      "INFO:tensorflow:input id: 2355 114 37 1091 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] After all you did on our farm ? You miss it , don't you Jesse ? [END]\n",
      "INFO:tensorflow:output id: 21 378 187 33 185 140 1174 3833 6 181 3564 100 23 116 33 6141 6 35 0 0\n",
      "INFO:tensorflow:input text: But , I don't understand .\n",
      "INFO:tensorflow:input id: 141 23 24 116 1031 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] And , I'm asking you to trust me without understanding why . [END]\n",
      "INFO:tensorflow:output id: 21 224 23 70 1224 33 92 396 184 892 2288 307 34 35 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: You could be quiet .\n",
      "INFO:tensorflow:input id: 181 82 93 2028 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Hi . [END]\n",
      "INFO:tensorflow:output id: 21 290 34 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: The interest is four hundred and fifty dollars a week on fifteen thousand ?\n",
      "INFO:tensorflow:input id: 67 2666 69 2177 693 9 678 1885 63 1112 140 5741 518 6 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] That's right . Three percent . [END]\n",
      "INFO:tensorflow:output id: 21 103 453 34 1884 9156 34 35 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: How important do you think sex is ?\n",
      "INFO:tensorflow:input id: 512 1615 191 33 234 1955 69 6 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Not very . [END]\n",
      "INFO:tensorflow:output id: 21 36 1321 34 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: You do . To get out of here . You're gonna be me .\n",
      "INFO:tensorflow:input id: 181 191 34 401 83 50 73 238 34 112 226 93 184 34 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] I don't wanna be you . I wanna go home . [END]\n",
      "INFO:tensorflow:output id: 21 24 116 132 93 33 34 24 132 133 341 34 35 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: Yeah .\n",
      "INFO:tensorflow:input id: 330 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] What do I want to do ? [END]\n",
      "INFO:tensorflow:output id: 21 194 191 24 117 92 191 6 35 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: What's that ?\n",
      "INFO:tensorflow:input id: 316 120 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] A Shot Caller . A boss , a Capo . He's running shit . [END]\n",
      "INFO:tensorflow:output id: 21 507 9761 22403 34 507 3238 23 63 22404 34 459 654 1101 34 35 0 0 0 0\n",
      "INFO:tensorflow:input text: Jeffrey ... this is wonderful .\n",
      "INFO:tensorflow:input id: 10189 44 4 69 2346 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] It is ? [END]\n",
      "INFO:tensorflow:output id: 21 301 69 6 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: I'm a scientist . I have lived my whole life by the diagnostic application of fact and the fact is\n",
      "INFO:tensorflow:input id: 70 63 9938 34 24 62 979 59 2228 313 510 37 26093 22871 73 2145 9 37 2145 69\n",
      "INFO:tensorflow:output text: [START] You mean the designs for the nanobot ? You think after this I'm going to give them to [END]\n",
      "INFO:tensorflow:output id: 21 181 244 37 26068 114 37 26054 6 181 234 1402 4 70 259 92 270 446 92 35\n",
      "INFO:tensorflow:input text: Yes .\n",
      "INFO:tensorflow:input id: 937 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Did the person you made love with satisfy you more than your husband ? [END]\n",
      "INFO:tensorflow:output id: 21 230 37 986 33 1522 1096 28 8777 33 206 813 209 3354 6 35 0 0 0 0\n",
      "INFO:tensorflow:input text: If we could lure him away from the bridge ...\n",
      "INFO:tensorflow:input id: 204 2 82 14716 145 392 501 37 3059 44 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] It doesn't matter where he is . As soon as he realizes something is happening , he'll override [END]\n",
      "INFO:tensorflow:output id: 21 301 142 529 125 236 69 34 370 1235 431 236 14521 349 69 1598 23 560 29192 35\n",
      "INFO:tensorflow:input text: It was a clumsy way to introduce myself - - but I understand you're a difficult man to see .\n",
      "INFO:tensorflow:input id: 301 101 63 12839 802 92 4080 200 19 19 134 24 1031 225 63 2955 574 92 462 34\n",
      "INFO:tensorflow:output text: [START] Not yet . That's why I wanted to see you . [END]\n",
      "INFO:tensorflow:output id: 21 36 1277 34 103 307 24 183 92 462 33 34 35 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: No ... She's fine . Back home .\n",
      "INFO:tensorflow:input id: 56 44 146 1812 34 369 341 34 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] What'll it be ? The regular ? Black Label ? [END]\n",
      "INFO:tensorflow:output id: 21 4969 100 93 6 67 3602 6 2391 32050 6 35 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: Enough . Cut him loose .\n",
      "INFO:tensorflow:input id: 3562 34 3556 145 3170 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] I can't ! At midnight tonight , he will kill again . It's crazy ! [END]\n",
      "INFO:tensorflow:output id: 21 24 135 203 1011 5676 1841 23 236 398 1793 1056 34 282 2425 203 35 0 0 0\n",
      "INFO:tensorflow:input text: ... Look , they love you , kid everybody does . You see Caven's review in the Herald ?\n",
      "INFO:tensorflow:input id: 44 973 23 473 1096 33 23 1758 1857 298 34 181 462 34506 14122 153 37 15275 6 0\n",
      "INFO:tensorflow:output text: [START] No , what did it say ? [END]\n",
      "INFO:tensorflow:output id: 21 56 23 325 185 100 119 6 35 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: Jesus Christ .\n",
      "INFO:tensorflow:input id: 1130 1049 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Oh , don't be such a fucking hypocrite . I quit smoking , didn't I ? [END]\n",
      "INFO:tensorflow:output id: 21 297 23 116 93 127 63 1515 26712 34 24 2409 3043 23 61 24 6 35 0 0\n",
      "INFO:tensorflow:input text: There's a lot of people here .\n",
      "INFO:tensorflow:input id: 801 63 812 73 397 238 34 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Nance gives me trouble and I'll tell him ... screw around with those suitcases and I'll take the [END]\n",
      "INFO:tensorflow:output id: 21 36864 1882 184 2351 9 285 381 145 44 7779 2142 28 589 35914 9 285 666 37 35\n",
      "INFO:tensorflow:input text: I work , just like you . You're more of a crook than I am , dude .\n",
      "INFO:tensorflow:input id: 24 1178 23 102 80 33 34 112 206 73 63 16441 813 24 1179 23 4855 34 0 0\n",
      "INFO:tensorflow:output text: [START] How do you figure ... HEY ! You can't roll a joint in here ! [END]\n",
      "INFO:tensorflow:output id: 21 512 191 33 3340 44 13896 203 181 135 4853 63 2495 153 238 203 35 0 0 0\n",
      "INFO:tensorflow:input text: Yes - - and that he ought to be up and around sometime soon .\n",
      "INFO:tensorflow:input id: 937 19 19 9 120 236 2131 92 93 20 9 2142 8446 1235 34 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Up and around ? Soon ? [END]\n",
      "INFO:tensorflow:output id: 21 4330 9 2142 6 3861 6 35 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: Have you been working with Rachel ?\n",
      "INFO:tensorflow:input id: 788 33 189 1684 28 25913 6 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] No . [END]\n",
      "INFO:tensorflow:output id: 21 56 34 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: You know what I mean .\n",
      "INFO:tensorflow:input id: 181 118 325 24 244 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] What do you want ? A statement of purpose ... ? [END]\n",
      "INFO:tensorflow:output id: 21 194 191 33 117 6 507 785 73 707 44 6 35 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: Whose orders are these ?\n",
      "INFO:tensorflow:input id: 1833 4116 12 837 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Mr . Hagen's , ma'am . [END]\n",
      "INFO:tensorflow:output id: 21 2789 34 42215 23 5263 34 35 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: And so , in a blazing fury , Charles runs Lancelot Trelawney through with his sword . . . leaving Deborah free\n",
      "INFO:tensorflow:input id: 224 156 23 153 63 23493 43412 23 5768 1902 40458 43413 495 28 577 8671 867 1222 31742 1254\n",
      "INFO:tensorflow:output text: [START] and HERBERT exchange a glance . HONORA smiles at Juliet . [END]\n",
      "INFO:tensorflow:output id: 21 9 43389 12034 63 2333 34 43392 21062 71 9943 34 35 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: We'll be done pretty soon ...\n",
      "INFO:tensorflow:input id: 1845 93 760 157 1235 44 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Tricky little devils , aren't they ? How's the degree doing ? [END]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:output id: 21 25116 474 9582 23 1121 473 6 2166 37 15249 348 6 35 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: Not pure evil . That's correct .\n",
      "INFO:tensorflow:input id: 36 2703 520 34 103 1810 34 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] And also that ... [END]\n",
      "INFO:tensorflow:output id: 21 224 1297 120 44 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: I'd like a little more conviction ..\n",
      "INFO:tensorflow:input id: 269 80 63 474 206 11171 2289 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] So would I . But it's not mine to give . [END]\n",
      "INFO:tensorflow:output id: 21 158 741 24 34 141 58 147 1217 92 270 34 35 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: With Hypnocyl ?\n",
      "INFO:tensorflow:input id: 1092 47518 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] That's right . [END]\n",
      "INFO:tensorflow:output id: 21 103 453 34 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: I can't believe Jim Hopper walked into an ambush .\n",
      "INFO:tensorflow:input id: 24 135 1339 4365 23942 3155 1233 14 6309 34 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] I don't believe he did , Sir . I couldn't find a single track . Just doesn't make [END]\n",
      "INFO:tensorflow:output id: 21 24 116 1339 236 185 23 1429 34 24 1558 857 63 3467 820 34 373 142 3 35\n",
      "INFO:tensorflow:input text: That's called changing your mind .\n",
      "INFO:tensorflow:input id: 103 1984 4327 209 383 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] No , that's called not having a mind of your own . What are you doing , Maggie [END]\n",
      "INFO:tensorflow:output id: 21 56 23 31 1984 147 13 63 383 73 209 350 34 194 12 33 348 23 31242 35\n",
      "INFO:tensorflow:input text: God . This is the kitchen , huh ?\n",
      "INFO:tensorflow:input id: 202 34 108 69 37 1579 23 972 6 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Yeah , this is it . How do you like it , Danny ? Is it big enough [END]\n",
      "INFO:tensorflow:output id: 21 330 23 4 69 100 34 512 191 33 80 100 23 10688 6 247 100 649 86 35\n",
      "INFO:tensorflow:input text: Who is ... ' V'ger ' ... ?\n",
      "INFO:tensorflow:input id: 164 69 44 47 51513 47 44 6 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] V'ger is that which programmed me . [END]\n",
      "INFO:tensorflow:output id: 21 51513 69 120 499 2969 184 34 35 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: In a few months he creates a revolutionary type of mircoprocessor .\n",
      "INFO:tensorflow:input id: 362 63 591 2586 236 13475 63 8224 885 73 52436 34 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] Then what ? [END]\n",
      "INFO:tensorflow:output id: 21 186 325 6 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: Those 80 acres , that cross the stream , what do you think of them ?\n",
      "INFO:tensorflow:input id: 3103 17531 15110 23 120 4065 37 11341 23 325 191 33 234 73 446 6 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] On your property ? [END]\n",
      "INFO:tensorflow:output id: 21 2743 209 9184 6 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input text: What are we gonna see ?\n",
      "INFO:tensorflow:input id: 194 12 2 226 462 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:output text: [START] A Donny Chiba triple feature . \" The Streetfighter \" , \" Return of the Streetfighter \" , [END]\n",
      "INFO:tensorflow:output id: 21 507 35420 54670 13776 15514 34 179 67 54674 179 23 179 17682 73 37 54674 179 23 35\n",
      "INFO:tensorflow:input text: I'm kidding , I'm kidding , we're still young , Darien . So what's money anyway when everybody's making it\n",
      "INFO:tensorflow:input id: 70 220 23 70 220 23 266 900 1507 23 55471 34 158 934 665 780 96 6878 635 100\n",
      "INFO:tensorflow:output text: [START] You got it all charted out don't you , like a stock projection . [END]\n",
      "INFO:tensorflow:output id: 21 181 274 100 187 16000 50 116 33 23 80 63 3337 52004 34 35 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "max_input_seq = 20\n",
    "max_output_seq = 20\n",
    "\n",
    "word_dict, examples = build_dataSet(movie_conver, movie_lines, max_input_seq, max_output_seq, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_example, val_examples = train_test_split(examples, test_size = 0.2, random_state = 3)\n",
    "save_data(train_example, 'data/train')\n",
    "save_data(val_examples, 'data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie_conver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f595bdfa3878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmovie_conver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmovie_lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtrain_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movie_conver' is not defined"
     ]
    }
   ],
   "source": [
    "del movie_conver\n",
    "del movie_lines\n",
    "del train_example, val_examples, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/vocab.json', 'w') as fp:\n",
    "    json.dump(word_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_DataSet(input_file, input_length, output_length, batch_size = 32, training = True):\n",
    "    \n",
    "    feature_description = {\n",
    "      \"input_ids\": tf.FixedLenFeature([input_length], tf.int64),\n",
    "      \"output_ids\": tf.FixedLenFeature([output_length], tf.int64),\n",
    "      }\n",
    "    \n",
    "    def _parse_function(record):\n",
    "        return tf.parse_single_example(record, feature_description)\n",
    "    \n",
    "    \n",
    "    data = tf.data.TFRecordDataset(input_file).map(lambda x: _parse_function(x)).cache()  \n",
    "    \n",
    "    if training:\n",
    "        data = data.shuffle(buffer_size=1000)\n",
    "        \n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_ids, vocab_size, embeding_size):\n",
    "    \n",
    "    embeding = tf.get_variable(name = 'word_embedding', shape = [vocab_size, embeding_size], dtype = tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "    input_embeding = tf.nn.embedding_lookup(embeding, input_ids)\n",
    "    \n",
    "    rnn_layers = [tf.nn.rnn_cell.GRUCell(size) for size in [512]]\n",
    "\n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "    \n",
    "    sequence_length = tf.reduce_sum(tf.cast(input_ids > 0, dtype = tf.int32), axis=-1)\n",
    "\n",
    "    outputs, state = tf.nn.dynamic_rnn(multi_rnn_cell, input_embeding, dtype=tf.float32, sequence_length = sequence_length)\n",
    "    \n",
    "    return outputs, state, sequence_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(attention_unit, encoder_output, sequence_length):\n",
    "    \n",
    "    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(attention_unit, memory = encoder_output,\n",
    "                                                               memory_sequence_length=sequence_length)\n",
    "    return attention_mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(output_ids, encoder_state, vocab_size, reuse = None, training = True):\n",
    "    \n",
    "    with tf.variable_scope('decoder', reuse = reuse):\n",
    "\n",
    "        embeding = tf.get_default_graph().get_tensor_by_name(\"word_embedding:0\")\n",
    "\n",
    "        input_embeding = tf.nn.embedding_lookup(embeding, output_ids)\n",
    "\n",
    "        rnn_layers = [tf.nn.rnn_cell.GRUCell(size) for size in [512]]\n",
    "\n",
    "        multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "        \n",
    "        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(attention_unit, encoder_output, encoder_length)\n",
    "\n",
    "        attention_cell = tf.contrib.seq2seq.AttentionWrapper(multi_rnn_cell, attention_mechanism, attention_layer_size = None)\n",
    "        \n",
    "        attention_cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "                attention_cell, vocab_size, reuse=reuse)\n",
    "        \n",
    "        batch_size = tf.shape(output_ids)[0]\n",
    "\n",
    "        initial_state = attention_cell.zero_state(dtype = tf.float32, batch_size = batch_size)\n",
    "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
    "\n",
    "        decoder_sequence_length = tf.reduce_sum(tf.cast(output_ids > 0, dtype = tf.int32), axis=-1)\n",
    "        \n",
    "        if training:\n",
    "            helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                        inputs = input_embeding,\n",
    "                        sequence_length = decoder_sequence_length)\n",
    "        else:\n",
    "            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embeding, start_tokens=tf.zeros([batch_size], dtype=tf.int32) + word_dict['[START]'], end_token=word_dict['[END]'])\n",
    "            \n",
    "\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell = attention_cell,\n",
    "                helper = helper, \n",
    "                initial_state = initial_state)\n",
    "\n",
    "        decoder_outputs, final_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "    \n",
    "    return decoder_outputs, final_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_loss(prediction, label, sequence_length_mask, vocab_size):\n",
    "    \n",
    "    one_hot_label =tf.one_hot(label, depth = vocab_size)\n",
    "    per_example_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels = one_hot_label, logits = prediction)\n",
    "    per_example_loss = per_example_loss * sequence_length_mask\n",
    "    \n",
    "    per_example_loss = tf.where(sequence_length_mask < 1, tf.stop_gradient(per_example_loss), per_example_loss)\n",
    "    per_example_loss = tf.reduce_mean(per_example_loss, axis = -1)\n",
    "    \n",
    "    return per_example_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/vocab.json', 'r') as fp:\n",
    "    word_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "train_file = 'data/train'\n",
    "val_file = 'data/val'\n",
    "input_length = 20\n",
    "output_length = 20\n",
    "batch_size = 32\n",
    "\n",
    "embeding_size = 300\n",
    "vocab_size = len(word_dict)\n",
    "attention_unit = 32\n",
    "\n",
    "train_data = load_DataSet(train_file, input_length, output_length, batch_size)\n",
    "# val_data = load_DataSet(val_file, input_length, output_length, batch_size, training = False)\n",
    "\n",
    "iter_ = tf.data.Iterator.from_structure(train_data.output_types, train_data.output_shapes)\n",
    "\n",
    "train_init_op = iter_.make_initializer(train_data)\n",
    "# test_init_op = iter_.make_initializer(val_data)\n",
    "features = iter_.get_next()\n",
    "\n",
    "input_ids = features['input_ids']\n",
    "output_ids = features['output_ids']\n",
    "\n",
    "encoder_output, encoder_state, encoder_length = encoder(input_ids, vocab_size, embeding_size)\n",
    "\n",
    "# attention_mechanism = attention(attention_unit, encoder_output, encoder_length)\n",
    "\n",
    "decoder_outputs, _ = decoder(output_ids, encoder_state, vocab_size = vocab_size)\n",
    "\n",
    "# infer_outputs, _  = decoder(output_ids, encoder_state, vocab_size = vocab_size, reuse = True, training = False)\n",
    "\n",
    "decoder_length = tf.cast(output_ids[:,:-1] > 0, dtype = tf.float32)\n",
    "\n",
    "prob = tf.nn.softmax(decoder_outputs.rnn_output, axis=-1)\n",
    "# prediction = infer_outputs.sample_id[:,:-1]\n",
    "prediction = decoder_outputs.sample_id[:,:-1]\n",
    "\n",
    "# per_example_loss  = tf.contrib.seq2seq.sequence_loss(decoder_outputs.rnn_output[:,:-1,:], output_ids[:,1:], \n",
    "#                                          weights = sequence_length, average_across_batch = False)\n",
    "\n",
    "per_example_loss = sequence_loss(decoder_outputs.rnn_output[:,:-1,:], output_ids[:,1:], decoder_length, vocab_size)\n",
    "\n",
    "loss, loss_update = tf.metrics.mean(values=per_example_loss)\n",
    "total_cost = tf.reduce_mean(per_example_loss)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer().minimize(total_cost)\n",
    "\n",
    "accuracy, accu_update = tf.metrics.accuracy(prediction, output_ids[:,1:], weights = decoder_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epoch):\n",
    "        begin = time.time()\n",
    "        \n",
    "        sess.run(train_init_op)\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        try: \n",
    "            while True:\n",
    "#                 _, _, los, accu = sess.run([train_op, accu_update, loss, accuracy])\n",
    "                _, _, los= sess.run([train_op, loss_update, loss])\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print('time cost for training % s ' % (time.time() - begin))\n",
    "#         begin = time.time()\n",
    "#         sess.run(test_init_op)\n",
    "#         try: \n",
    "#             while True:\n",
    "                \n",
    "#                 _, accura= sess.run([accu_update, accuracy])\n",
    "#         except tf.errors.OutOfRangeError:\n",
    "#             pass\n",
    "#         print('loss in traing set at epoch %s is %s, accuracy is %s' % (i, los, accura))\n",
    "#         print('time cost for infer % s ' % (time.time() - begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
